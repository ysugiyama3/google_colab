{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "yale_dup_search.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOqaWBLaOPhKQidQWQn2Ckq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ysugiyama3/google_colab/blob/master/yale_dup_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hccZRWcgnpqM"
      },
      "source": [
        "## **Search Voyager records by ISBN**\n",
        "This program automatically searches Voyager records by ISBN found in the first sheet of an Excel spreadsheet. The first column must be assigned for ISBN. The spreadsheet can have as many columns as necesary and must have column headers.\n",
        "\n",
        "(Contact yukari.sugiyama@yale.edu if you have any questions)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "n16QOtgQ6dmr"
      },
      "source": [
        "#@title <--- Click the play button\n",
        "\n",
        "from pandas.core.common import index_labels_to_array\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import requests\n",
        "import json\n",
        "from IPython.display import HTML, display\n",
        "import time\n",
        "import re\n",
        "\n",
        "#===============================================================================\n",
        "# defs\n",
        "#===============================================================================\n",
        "\n",
        "def progress(value, max=50000):\n",
        "    return HTML(\"\"\"\n",
        "        <progress\n",
        "            value='{value}'\n",
        "            max='{max}',\n",
        "            style='width: 40%'\n",
        "        >\n",
        "            {value}\n",
        "        </progress>\n",
        "        <br>{value}/{max}</br>\n",
        "    \"\"\".format(value=value, max=max))\n",
        "\n",
        "def clean_isbn(isbn):\n",
        "    if isbn is None or pd.isnull(isbn):\n",
        "        isbn = None\n",
        "    elif len(str(isbn)) > 0:\n",
        "        isbn = str(isbn)\n",
        "        isbn = re.sub(r'[\\(|\\:|\\.].*', '', isbn)\n",
        "        isbn = re.sub(r'[^0-9Xx]', '', isbn) \n",
        "    else:\n",
        "        isbn = None\n",
        "    return isbn\n",
        "\n",
        "def get_item_info(item):\n",
        "    note = mfhdid = callno = itemid = enum = locname = status = ''\n",
        "    mfhdid = item['mfhdid']\n",
        "    callno = item['callno']\n",
        "    itemid = item['itemid']\n",
        "    if itemid == 'NA':\n",
        "        note = 'Held (but no item records)'\n",
        "    else:\n",
        "        enum = item['itemenum']\n",
        "        locname = item['locname']\n",
        "        status = item['itemstatus']\n",
        "        note = 'Held'\n",
        "    return note, mfhdid, callno, itemid, enum, locname, status\n",
        "\n",
        "def check_records(records):\n",
        "    global output_df\n",
        "    for record in records:\n",
        "        bibid = record['bibid']\n",
        "        try:\n",
        "            title = record['title']   \n",
        "            items = record['items']\n",
        "            for item in items:\n",
        "                note, mfhdid, callno, itemid, enum, locname, status = get_item_info(item)\n",
        "                output_df = output_df.append([input_df.iloc[index]],ignore_index=True)\n",
        "                current_index_loc = output_df.index.size-1\n",
        "                output_df.loc[current_index_loc, ['[NOTE]', '[BIB_ID]', '[TITLE]', '[MFHD_ID]', '[CALL_NO]', '[ITEM_ID]', '[ENUM]', '[LOCATION]', '[STATUS]']] = [note, bibid, title, mfhdid, callno, itemid, enum, locname, status]\n",
        "        except:\n",
        "            note = 'Check manually'\n",
        "            output_df = output_df.append([input_df.iloc[index]],ignore_index=True)\n",
        "            current_index_loc = output_df.index.size-1\n",
        "            output_df.loc[current_index_loc, '[NOTE]'] = note\n",
        "\n",
        "def search_opac(isbn):\n",
        "    global output_df\n",
        "    number = index + 0.01\n",
        "    if isbn is None or pd.isnull(isbn):\n",
        "        note = 'No ISBN'\n",
        "        output_df = output_df.append([input_df.iloc[index]],ignore_index=True)\n",
        "        current_index_loc = output_df.index.size-1\n",
        "        output_df.loc[current_index_loc, '[NOTE]'] = note\n",
        "    else:\n",
        "        url = 'http://libapp-test.library.yale.edu/VoySearch/GetBibItem?isxn=' + str(isbn)\n",
        "        r = requests.get(url)\n",
        "        result = json.loads(r.text)\n",
        "        records= result['record']\n",
        "        check_records(records)\n",
        "\n",
        "#===============================================================================\n",
        "# main\n",
        "#===============================================================================\n",
        "\n",
        "!pip install --upgrade xlrd\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "# Upload an input Excel file\n",
        "uploaded = files.upload()\n",
        "input_name = str(list(uploaded.keys())[0])\n",
        "\n",
        "# Read an input Excel file into a pandas DataFrame\n",
        "input_df = pd.read_excel(input_name)\n",
        "\n",
        "# Create an output Excel file based on input excel file\n",
        "output_name = input_name.rsplit( \".\", 1 )[0] + \"_output.xlsx\"\n",
        "\n",
        "# Create an output DataFrame\n",
        "output_df = pd.DataFrame(columns=input_df.columns)\n",
        "output_df = pd.concat([output_df, pd.DataFrame(columns = ['[NOTE]', '[BIB_ID]', '[TITLE]', '[MFHD_ID]', '[CALL_NO]', '[ITEM_ID]', '[ENUM]', '[LOCATION]', '[STATUS]'])], sort=False)\n",
        "\n",
        "# count\n",
        "total = input_df.index.size\n",
        "count = 0\n",
        "\n",
        "out = display(progress(0, total), display_id=True)\n",
        "\n",
        "for index, row in input_df.iterrows():\n",
        "    count += 1\n",
        "    time.sleep(0.02)\n",
        "    out.update(progress(count, total))\n",
        "    isbn = row[0]\n",
        "    isbn = clean_isbn(isbn)\n",
        "    try:\n",
        "        search_opac(isbn)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "try:\n",
        "    output_df.to_excel(output_name, index=False)\n",
        "except:\n",
        "    csv_output_name = output_name.rsplit( \".\", 1 )[0] + '.csv'\n",
        "    output_df.to_csv(csv_output_name, index=False, encoding='utf-8')\n",
        "\n",
        "print('\\nDone!')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}